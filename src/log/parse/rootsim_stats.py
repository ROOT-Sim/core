#!/usr/bin/env python3
# SPDX-FileCopyrightText: 2008-2021 HPDCS Group <rootsim@googlegroups.com>
# SPDX-License-Identifier: GPL-3.0-only
import copy
import struct
import sys


##
# @brief The statistics class used to load and pre-process ROOT-Sim statistics files
#
# If you configured ROOT-Sim to produce a statistics file, a binary file will be generated.
# You can use the facilities offered by this class to efficiently load those statistics.
# TODO provide also statistics normalized by wall clock time
# TODO document class APIs
class RSStats:
    _STATS_MAX_STRLEN = 32

    def _pattern_unpack(self, ptrn):
        ptrn_size = struct.calcsize(ptrn)
        data_parse = self._data[self._data_idx:ptrn_size + self._data_idx]
        self._data_idx += ptrn_size
        ret = struct.unpack((">" if self.big_endian else "<") + ptrn, data_parse)
        return ret

    def _metric_names_load(self):
        metric_names = []
        n_stats = self._pattern_unpack("q")[0]
        for _ in range(n_stats):
            raw_name = self._pattern_unpack(f"{RSStats._STATS_MAX_STRLEN}s")[0]
            metric_name = raw_name.decode("utf-8").rstrip('\0')
            metric_names.append(metric_name)
            self._metrics[metric_name] = []
        return metric_names

    def _threads_unpack(self):
        metrics_len = len(self.metrics)
        n_stats = self._pattern_unpack("q")[0] // (metrics_len * 8)
        t_stats_fmt = str(metrics_len) + "Q"
        ret = []
        for _ in range(n_stats):
            ret.append(self._pattern_unpack(t_stats_fmt))
        return ret

    def _nodes_stats_load(self):
        self.nodes_count = self._pattern_unpack("q")[0]
        for _ in range(self.nodes_count):
            glob_stats = self._pattern_unpack("8Q")
            n_threads = glob_stats[0]
            self.threads_count.append(n_threads)
            n_stats = self._pattern_unpack("q")[0] // 16
            node_stats = []
            for _ in range(n_stats):
                node_stats.append(self._pattern_unpack("dQ"))

            threads_stats = []
            for _ in range(n_threads):
                threads_stats.append(self._threads_unpack())

            self.all_stats.append((glob_stats, node_stats, threads_stats))

    def _truncate_to_last_gvt(self):
        min_gvts = len(self.all_stats[0][1])
        for _, node_stats, threads_stats in self.all_stats:
            min_gvts = min(len(node_stats), min_gvts)
            for t_stats in threads_stats:
                min_gvts = min(len(t_stats), min_gvts)

        ret = []
        for glob_stats, node_stats, threads_stats in self.all_stats:
            t_node_stats = node_stats[:min_gvts]
            t_threads_stats = []
            for t_stats in threads_stats:
                t_threads_stats.append(t_stats[:min_gvts])
            ret.append((glob_stats, t_node_stats, t_threads_stats))

        self.all_stats = ret

    ##
    # @brief Construct a new RSStats object
    # @param self the RSStats instance being constructed
    # @param rs_stats_file the path of the binary statistics file generated by ROOT-Sim
    def __init__(self, rs_stats_file):
        with open(rs_stats_file, 'rb') as f:
            self._data = f.read()

        self._data_idx = 0
        self.big_endian = True
        magic_number = self._pattern_unpack("H")[0]
        if magic_number == 61455 or magic_number == 4080:
            self.big_endian = magic_number == 61455
        else:
            raise RuntimeWarning("Parsing failed, wrong initial magic number")

        self._metrics = {}
        metric_names = self._metric_names_load()

        self.threads_count = []
        self.all_stats = []
        self._nodes_stats_load()

        if len(self._data) != self._data_idx:
            raise RuntimeWarning("Parsing failed, there's garbage at the end")

        self._gvts = []
        self._truncate_to_last_gvt()

        self._global_measures = []
        for triple in self.all_stats:
            glob_stats, node_stats, threads_stats = triple

            this_measures = {
                "maximum_resident_set": glob_stats[1],
                "node_init_time": glob_stats[3] - glob_stats[2],
                "worker_threads_init_time": glob_stats[4] - glob_stats[3],
                "processing_time": glob_stats[5] - glob_stats[4],
                "worker_threads_fini_time": glob_stats[6] - glob_stats[5],
                "node_fini_time": glob_stats[7] - glob_stats[6]
            }

            mem = []
            for i, (gvt, crs_mem) in enumerate(node_stats):
                if len(self._gvts) <= i:
                    self._gvts.append(gvt)
                elif self._gvts[i] != gvt:
                    raise RuntimeWarning("Parsing failed, inconsistent GVTs across nodes and/or threads")

                mem.append(crs_mem)

            this_measures["resident_set"] = mem
            self._global_measures.append(this_measures)

            for j, metric_name in enumerate(metric_names):
                metric_n_stat = []
                for t_stat in threads_stats:
                    metric_t_stat = []
                    for tup in t_stat:
                        metric_t_stat.append(tup[j])
                    metric_n_stat.append(metric_t_stat)

                self._metrics[metric_name].append(metric_n_stat)

    ##
    # @brief Get the GVT values
    # @return a list containing the computed GVTs (Global Virtual Times) in ascending order
    @property
    def gvts(self):
        return list(self._gvts)

    ##
    # @brief Get the thread-specific metric names
    # @return a list containing the metric names that you can use in #thread_metric_get()
    @property
    def metrics(self):
        return list(self._metrics)

    ##
    # @brief Get the node-specific statistics
    # @return a dictionary containing node-specific statistics
    # TODO more thorough description of what we have here
    @property
    def node_stats(self):
        return list(self._global_measures)

    @property
    def nodes_count(self):
        return len(self.threads_count)

    ##
    # @brief Get the thread-specific metric values
    # @return a list of values FIXME: much more complicated, explain it!
    def thread_metric_get(self, metric, aggregate_gvts=False,
                          aggregate_threads=False, aggregate_nodes=False):
        if metric not in self._metrics:
            raise RuntimeError(f"Asked stats for the non-existing thread_metric {metric}")

        if aggregate_nodes:
            aggregate_threads = True

        this_stats = copy.deepcopy(self._metrics[metric])

        if aggregate_gvts:
            for nstats in this_stats:
                for i, _ in enumerate(nstats):
                    nstats[i] = sum(nstats[i])

            if aggregate_threads:
                for i, _ in enumerate(this_stats):
                    this_stats[i] = sum(this_stats[i])

                if aggregate_nodes:
                    this_stats = sum(this_stats)
        else:
            if aggregate_threads:
                for i, _ in enumerate(this_stats):
                    gvt_stats = [0] * len(self._gvts)
                    for rstats in this_stats[i]:
                        for j, val in enumerate(rstats):
                            gvt_stats[j] += val
                    this_stats[i] = gvt_stats

                if aggregate_nodes:
                    gvt_stats = [0] * len(self._gvts)
                    for nstats in this_stats:
                        for j, val in enumerate(nstats):
                            gvt_stats[j] += val
                    this_stats = gvt_stats

        return this_stats


# Produce a boring textual report
if __name__ == "__main__":
    if len(sys.argv) != 2:
        print("Please, supply the name of the raw statistics file!", file=sys.stderr)
        exit(-1)

    stats = RSStats(sys.argv[1])

    processed_msgs = stats.thread_metric_get("processed messages", aggregate_nodes=True, aggregate_gvts=True)
    rollbacked_msgs = stats.thread_metric_get("rolled back messages", aggregate_nodes=True, aggregate_gvts=True)
    silent_msgs = stats.thread_metric_get("silent messages", aggregate_nodes=True, aggregate_gvts=True)
    rollbacks = stats.thread_metric_get("rollbacks", aggregate_nodes=True, aggregate_gvts=True)

    outname = sys.argv[1][4:] if sys.argv[1].endswith(".bin") else sys.argv[1]
    outname = outname + ".txt"

    with open(outname, "w") as f:
        f.write(f"TOTAL KERNELS ............. : {stats.nodes_count}\n")
        f.write(f"TOTAL_THREADS ............. : {sum(stats.threads_count)}\n")
        f.write(f"TOTAL_LPs ................. : TODO\n")  # TODO add number of LPs to stats in ROOT-Sim!
        f.write(f"TOTAL EXECUTED EVENTS ..... : {processed_msgs + silent_msgs}\n")
        f.write(f"TOTAL COMMITTED EVENTS..... : {processed_msgs - rollbacked_msgs}\n")
        f.write(f"TOTAL REPROCESSED EVENTS... : {rollbacked_msgs}\n")
        f.write(f"TOTAL SILENT EVENTS........ : {silent_msgs}\n")
        f.write(f"TOTAL ROLLBACKS EXECUTED... : {rollbacks}\n")
        f.write(f"TOTAL ANTIMESSAGES......... : TODO\n")  # TODO add antimessages to stats in ROOT-Sim!
        f.write(f"ROLLBACK FREQUENCY......... : {100 * rollbacked_msgs / processed_msgs}%\n")
        f.write(f"ROLLBACK LENGTH............ : {rollbacked_msgs / rollbacks}\n")
        f.write(f"EFFICIENCY................. : {100 * (processed_msgs - rollbacked_msgs) / processed_msgs}%\n")
        f.write(f"AVERAGE EVENT COST......... : TODO\n")  # TODO do we want this?
        f.write(f"AVERAGE EVENT COST (EMA)... : TODO\n")  # TODO do we want this?
        f.write(f"AVERAGE CHECKPOINT COST.... : TODO\n")  # TODO do we want this?
        f.write(f"AVERAGE RECOVERY COST...... : TODO\n")  # TODO do we want this?
        f.write(f"AVERAGE LOG SIZE........... : TODO\n")  # TODO add log size to stats in ROOT-Sim!
        f.write(f"IDLE CYCLES................ : TODO\n")  # TODO do we want this?
        f.write(f"LAST COMMITTED GVT ........ : {stats.gvts[-1]}\n")
        f.write(f"NUMBER OF GVT REDUCTIONS... : {len(stats.gvts)}\n")
        f.write(f"MIN GVT ROUND TIME......... : TODO\n")  # TODO do we want this?
        f.write(f"MAX GVT ROUND TIME......... : TODO\n")  # TODO do we want this?
        f.write(f"AVERAGE GVT ROUND TIME..... : TODO\n")  # TODO do we want this?
        f.write(f"SIMULATION TIME SPEED...... : {stats.gvts[-1] / len(stats.gvts)}\n")
        f.write(f"AVERAGE MEMORY USAGE....... : TODO\n")  # TODO get from stats
        f.write(f"PEAK MEMORY USAGE.......... : TODO\n")  # TODO get from stats
